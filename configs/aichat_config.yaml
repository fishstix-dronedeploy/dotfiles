# see https://github.com/sigoden/aichat/blob/main/config.example.yaml

model: ollama:llama3
clients:
- type: openai-compatible
  name: ollama
  api_base: http://localhost
  models:
  - name: llama3
